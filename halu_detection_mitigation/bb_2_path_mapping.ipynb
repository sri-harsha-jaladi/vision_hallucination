{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cb50788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "448dfbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import math\n",
    "from typing import List, Dict, Tuple, Union\n",
    "\n",
    "BBox = Union[Dict[str, float], Dict[str, int], Tuple[float, float, float, float], List[float]]\n",
    "\n",
    "def _coerce_bbox(b: BBox) -> Tuple[float, float, float, float]:\n",
    "    if isinstance(b, (list, tuple)) and len(b) == 4:\n",
    "        return float(b[0]), float(b[1]), float(b[2]), float(b[3])\n",
    "    if isinstance(b, dict):\n",
    "        keys = {k.lower(): k for k in b.keys()}\n",
    "        def g(k):\n",
    "            for cand in (k, k.replace('main', 'min')):  # tolerate 'ymain' -> 'ymin'\n",
    "                if cand in keys:\n",
    "                    return float(b[keys[cand]])\n",
    "            raise KeyError(f\"Missing key {k} in bbox dict: {b}\")\n",
    "        return g('xmin'), g('ymin'), g('xmax'), g('ymax')\n",
    "    raise TypeError(f\"Unsupported bbox format: {type(b)}\")\n",
    "\n",
    "def bbox_patch_binary_masks(\n",
    "    image_w: int,\n",
    "    image_h: int,\n",
    "    bboxes: Union[BBox, List[BBox]],\n",
    "    patch_w: int = 14,\n",
    "    patch_h: int = None,\n",
    "    *,\n",
    "    inclusive_xymax: bool = False\n",
    ") -> List[List[int]]:\n",
    "    \"\"\"\n",
    "    For a W×H image split into patch_w×patch_h patches (row-major),\n",
    "    return, for each bbox, a flat 0/1 list of length (num_rows*num_cols)\n",
    "    marking patches that intersect the bbox.\n",
    "\n",
    "    Args:\n",
    "        image_w, image_h: image size in pixels (e.g., 336, 336)\n",
    "        bboxes: single bbox or list of bboxes. Each bbox can be:\n",
    "                - dict with keys xmin,ymin,xmax,ymax (case-insensitive; 'ymain' tolerated)\n",
    "                - list/tuple [xmin, ymin, xmax, ymax]\n",
    "        patch_w, patch_h: patch size in pixels (default 14×14). If patch_h is None, uses patch_w.\n",
    "        inclusive_xymax: treat (xmax,ymax) as inclusive if True; exclusive if False.\n",
    "\n",
    "    Returns:\n",
    "        List of binary masks (one per bbox). Each mask is a list[int] of length num_rows*num_cols.\n",
    "        Indexing is row-major: idx = row * num_cols + col.\n",
    "    \"\"\"\n",
    "    if patch_h is None:\n",
    "        patch_h = patch_w\n",
    "\n",
    "    num_cols = math.ceil(image_w / patch_w)\n",
    "    num_rows = math.ceil(image_h / patch_h)\n",
    "    total_patches = num_rows * num_cols\n",
    "\n",
    "    # Normalize to list of bboxes\n",
    "    if isinstance(bboxes, list) and not (len(bboxes) == 4 and all(isinstance(v, (int, float)) for v in bboxes)):\n",
    "        bbox_list = bboxes\n",
    "    else:\n",
    "        bbox_list = [bboxes]\n",
    "\n",
    "    masks: List[List[int]] = []\n",
    "\n",
    "    for b in bbox_list:\n",
    "        x0, y0, x1, y1 = _coerce_bbox(b)\n",
    "        if inclusive_xymax:\n",
    "            x1 += 1.0\n",
    "            y1 += 1.0\n",
    "\n",
    "        # Clamp to image bounds\n",
    "        x0 = max(0.0, min(x0, float(image_w)))\n",
    "        y0 = max(0.0, min(y0, float(image_h)))\n",
    "        x1 = max(0.0, min(x1, float(image_w)))\n",
    "        y1 = max(0.0, min(y1, float(image_h)))\n",
    "\n",
    "        # Degenerate -> all zeros\n",
    "        if x1 <= x0 or y1 <= y0:\n",
    "            masks.append([0] * total_patches)\n",
    "            continue\n",
    "\n",
    "        # Candidate patch span\n",
    "        col_start = int(math.floor(x0 / patch_w))\n",
    "        col_end   = int(math.ceil (x1 / patch_w) - 1)\n",
    "        row_start = int(math.floor(y0 / patch_h))\n",
    "        row_end   = int(math.ceil (y1 / patch_h) - 1)\n",
    "\n",
    "        col_start = max(0, min(col_start, num_cols - 1))\n",
    "        col_end   = max(0, min(col_end,   num_cols - 1))\n",
    "        row_start = max(0, min(row_start, num_rows - 1))\n",
    "        row_end   = max(0, min(row_end,   num_rows - 1))\n",
    "\n",
    "        mask = [0] * total_patches\n",
    "\n",
    "        # Mark intersecting patches\n",
    "        for r in range(row_start, row_end + 1):\n",
    "            for c in range(col_start, col_end + 1):\n",
    "                patch_x0 = c * patch_w\n",
    "                patch_y0 = r * patch_h\n",
    "                patch_x1 = min(patch_x0 + patch_w, image_w)\n",
    "                patch_y1 = min(patch_y0 + patch_h, image_h)\n",
    "\n",
    "                inter_w = max(0.0, min(x1, patch_x1) - max(x0, patch_x0))\n",
    "                inter_h = max(0.0, min(y1, patch_y1) - max(y0, patch_y0))\n",
    "                if inter_w > 0.0 and inter_h > 0.0:\n",
    "                    idx = r * num_cols + c\n",
    "                    mask[idx] = 1\n",
    "\n",
    "        masks.append(mask)\n",
    "\n",
    "    return masks\n",
    "\n",
    "\n",
    "\n",
    "def combine_mask_tensor(masks: List[List[int]], *, out_dtype=torch.uint64) -> torch.Tensor:\n",
    "    if len(masks) == 0:\n",
    "        return torch.empty((0,), dtype=out_dtype)\n",
    "    mask_tensor = torch.as_tensor(masks, dtype=out_dtype)\n",
    "    \n",
    "    if mask_tensor.numel() == 0:\n",
    "        # Empty input -> empty output\n",
    "        return torch.empty((mask_tensor.shape[-1] if mask_tensor.ndim == 2 else 0,), \n",
    "                           dtype=out_dtype, device=mask_tensor.device)\n",
    "\n",
    "    # Normalize to bool\n",
    "    mask_bool = (mask_tensor != 0) if mask_tensor.dtype != torch.bool else mask_tensor\n",
    "    # Row-wise OR -> single row\n",
    "    combined_bool = torch.any(mask_bool, dim=0)\n",
    "    return combined_bool.to(out_dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1aeeb44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Data2/Arun-UAV/NLP/vision_halu/evidence_head_train_datasets/coco_long_captions/coco_img_des_10k_bb_annot.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e55fa1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>target_words</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COCO_train2014_000000557315.jpg</td>\n",
       "      <td>Please describe this image in detail.</td>\n",
       "      <td>This outdoor scene captures a black bear in wh...</td>\n",
       "      <td>[{'word': 'black', 'class': 'attribute', 'bbox...</td>\n",
       "      <td>/Data2/Arun-UAV/NLP/vision_halu/train_datasets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COCO_train2014_000000106639.jpg</td>\n",
       "      <td>Please describe this image in detail.</td>\n",
       "      <td>The image presents an inviting indoor scene, l...</td>\n",
       "      <td>[{'word': 'dining', 'class': 'attribute', 'bbo...</td>\n",
       "      <td>/Data2/Arun-UAV/NLP/vision_halu/train_datasets...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          image_id                               question  \\\n",
       "0  COCO_train2014_000000557315.jpg  Please describe this image in detail.   \n",
       "1  COCO_train2014_000000106639.jpg  Please describe this image in detail.   \n",
       "\n",
       "                                              answer  \\\n",
       "0  This outdoor scene captures a black bear in wh...   \n",
       "1  The image presents an inviting indoor scene, l...   \n",
       "\n",
       "                                        target_words  \\\n",
       "0  [{'word': 'black', 'class': 'attribute', 'bbox...   \n",
       "1  [{'word': 'dining', 'class': 'attribute', 'bbo...   \n",
       "\n",
       "                                          image_path  \n",
       "0  /Data2/Arun-UAV/NLP/vision_halu/train_datasets...  \n",
       "1  /Data2/Arun-UAV/NLP/vision_halu/train_datasets...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8de9dc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'xmin': 174, 'ymin': 308, 'xmax': 234, 'ymax': 458},\n",
       " {'xmin': 107, 'ymin': 347, 'xmax': 164, 'ymax': 487},\n",
       " {'xmin': 276, 'ymin': 268, 'xmax': 303, 'ymax': 305},\n",
       " {'xmin': 291, 'ymin': 278, 'xmax': 324, 'ymax': 308}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(data[\"target_words\"].iloc[100])[3][\"bbox\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f9483097",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "boxes = eval(data[\"target_words\"].iloc[100])[3][\"bbox\"]\n",
    "masks = bbox_patch_binary_masks(bboxes = boxes, image_w=336, image_h=336, patch_w=14)\n",
    "combined_from_lists = combine_mask_tensor(masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d0b6dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77ed13b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shdm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
