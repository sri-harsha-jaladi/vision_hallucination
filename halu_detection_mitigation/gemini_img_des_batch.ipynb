{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "552c53cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from google import genai\n",
    "\n",
    "from google.oauth2.service_account import Credentials\n",
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "\n",
    "scopes = [\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    "SERVICE_ACCOUNT_FILE = \"/Data2/Arun-UAV/NLP/new_cloud_coount.json\"\n",
    "credentials = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=scopes)\n",
    "\n",
    "client = storage.Client(credentials=credentials)\n",
    "\n",
    "gen_client = genai.Client(\n",
    "    vertexai=True,\n",
    "    project='third-apex-476512-a7',   # or set directly\n",
    "    location='us-central1',    # or set directly, e.g. \"us-central1\"\n",
    "    credentials=credentials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d24b54b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "\n",
    "def load_coco(annotation_json_path):\n",
    "    \"\"\"\n",
    "    Load COCO annotations file and return a COCO object.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(annotation_json_path):\n",
    "        raise FileNotFoundError(f\"Annotation file not found: {annotation_json_path}\")\n",
    "    return COCO(annotation_json_path)\n",
    "\n",
    "def xywh_to_xyxy(bxy):\n",
    "    \"\"\"\n",
    "    Convert COCO bbox [x, y, w, h] -> [xmin, ymin, xmax, ymax] (integers)\n",
    "    \"\"\"\n",
    "    x, y, w, h = bxy\n",
    "    xmin = int(round(x))\n",
    "    ymin = int(round(y))\n",
    "    xmax = int(round(x + w))\n",
    "    ymax = int(round(y + h))\n",
    "    return [xmin, ymin, xmax, ymax]\n",
    "\n",
    "def get_objects_for_images(coco, image_ids=None, file_names=None, include_segmentation=False):\n",
    "    \"\"\"\n",
    "    Return object annotations for the given images (by image_ids or file_names).\n",
    "    Output format:\n",
    "      {\n",
    "        <image_id>: {\n",
    "            \"file_name\": <str>,\n",
    "            \"width\": <int>,\n",
    "            \"height\": <int>,\n",
    "            \"annotations\": [\n",
    "                {\n",
    "                  \"ann_id\": <annotation_id>,\n",
    "                  \"category_id\": <int>,\n",
    "                  \"category_name\": <str>,\n",
    "                  \"bbox_xywh\": [x,y,w,h],\n",
    "                  \"bbox_xyxy\": [xmin,ymin,xmax,ymax],\n",
    "                  \"area\": <float>,\n",
    "                  \"iscrowd\": <0/1>,\n",
    "                  \"segmentation\": <...> (optional)\n",
    "                }, ...\n",
    "            ]\n",
    "        }, ...\n",
    "      }\n",
    "    \"\"\"\n",
    "    # resolve image ids if file_names provided\n",
    "    ids = []\n",
    "    if file_names:\n",
    "        for fn in file_names:\n",
    "            results = coco.getImgIds(imgIds=[], file_name=fn)\n",
    "            if len(results) == 0:\n",
    "                # try matching by partial name or raise\n",
    "                raise ValueError(f\"No image found with file_name '{fn}' in COCO annotations\")\n",
    "            ids.extend(results)\n",
    "    if image_ids:\n",
    "        ids.extend(image_ids)\n",
    "    if not ids:\n",
    "        raise ValueError(\"Provide image_ids or file_names (or both)\")\n",
    "\n",
    "    out = {}\n",
    "    cat_map = {c['id']: c['name'] for c in coco.loadCats(coco.getCatIds())}\n",
    "\n",
    "    for img_id in ids:\n",
    "        img_info = coco.loadImgs(img_id)[0]\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        anns = coco.loadAnns(ann_ids)\n",
    "        ann_list = []\n",
    "        for a in anns:\n",
    "            obj = {\n",
    "                \"ann_id\": a.get(\"id\"),\n",
    "                \"category_id\": a.get(\"category_id\"),\n",
    "                \"category_name\": cat_map.get(a.get(\"category_id\"), \"unknown\"),\n",
    "                \"bbox_xywh\": a.get(\"bbox\"),  # [x,y,w,h]\n",
    "                \"bbox_xyxy\": xywh_to_xyxy(a.get(\"bbox\")),\n",
    "                \"area\": a.get(\"area\"),\n",
    "                \"iscrowd\": a.get(\"iscrowd\", 0),\n",
    "            }\n",
    "            if include_segmentation:\n",
    "                obj[\"segmentation\"] = a.get(\"segmentation\")\n",
    "            ann_list.append(obj)\n",
    "\n",
    "        out[img_id] = {\n",
    "            \"file_name\": img_info.get(\"file_name\"),\n",
    "            \"width\": img_info.get(\"width\"),\n",
    "            \"height\": img_info.get(\"height\"),\n",
    "            \"annotations\": ann_list\n",
    "        }\n",
    "    return out\n",
    "\n",
    "# ----------------------------\n",
    "# Example usage:\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c00fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ANNO = \"/Data2/Arun-UAV/NLP/vision_halu/train_datasets/annotations/instances_train2017.json\"   # change to your path\n",
    "coco = load_coco(ANNO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c00a9cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv(\"/Data2/Arun-UAV/NLP/vision_halu/hal_detection_head_train_datasets/coco/gemini_labeld_15k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "387aa51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=14574, step=1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bdbefb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14574/14574 [00:27<00:00, 532.03it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "all_object_info = []\n",
    "all_req_info = []\n",
    "failed = []\n",
    "for inx, row in tqdm(final_df.iterrows(), total=final_df.shape[0]):\n",
    "    try:\n",
    "        image_id = int(row[\"image_id\"].strip(\".jpg\").split(\"_\")[-1])\n",
    "        results = get_objects_for_images(coco, image_ids=[image_id])\n",
    "        object_df = pd.DataFrame(results[image_id][\"annotations\"])\n",
    "        req_df = object_df[[\"category_id\", \"category_name\"]].drop_duplicates()\n",
    "        req_df.columns = [\"object_id\", \"object\"]\n",
    "        \n",
    "        all_object_info.append(object_df.to_dict(orient=\"records\"))\n",
    "        all_req_info.append(req_df.to_dict(orient=\"records\"))\n",
    "    except Exception as e:\n",
    "        failed.append(inx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e14b6cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.drop(index=failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "446307ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=14435, step=1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "111adff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"object_info\"] = all_object_info\n",
    "final_df[\"req_info\"] = all_req_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "330dec99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14435"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[\"answer\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19e1cf0",
   "metadata": {},
   "source": [
    "# batch creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c8b909d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14435it [00:00, 15128.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def get_prompt(question, answer, objects_info, candidate_tokens):\n",
    "    prompt = f\"\"\"\n",
    "You are given:\n",
    "\n",
    "* A **question** about an image\n",
    "* Its **answer**\n",
    "* A list of **candidate tokens** extracted from the answer.\n",
    "  Each candidate token belongs to one of the following classes:\n",
    "  **objects, attributes, relations, actions, count, decision tokens.**\n",
    "* A set of **objects present in the image** with their unique **object IDs**.\n",
    "\n",
    "Your task is to **assign a list of relevant object IDs** to each candidate token based on semantic meaning and contextual relevance in the answer.\n",
    "Follow these rules carefully:\n",
    "\n",
    "1. **Objects:** link to their exact object ID.\n",
    "2. **Attributes:** assign the ID of the object that expresses this attribute (e.g., â€œredâ€ â†’ object that is red).\n",
    "3. **Relations:** assign IDs of all objects involved (e.g., â€œonâ€ â†’ [table_id, cup_id]).\n",
    "4. **Actions:** assign IDs of the object(s) performing or receiving the action.\n",
    "5. **Count:** assign IDs of all objects being counted.\n",
    "6. **Decision tokens (yes, no, true, false, exist, not, visible, etc.):** assign all relevant IDs if contextually grounded, else leave as `[-1]`.\n",
    "7. If a candidateâ€™s corresponding object class **does not appear** in the given object list, label it as `[-1]`.\n",
    "\n",
    "Note: while matching objects, consider symantical meaning no need to be exact match\n",
    "\n",
    "### ðŸ§¾ **Expected Output Format**\n",
    "\n",
    "```json\n",
    "[\n",
    "  {{\"word\": \"red\", \"class\": \"attribute\", \"object_ids\": [12]}},\n",
    "  {{\"word\": \"on\", \"class\": \"relation\", \"object_ids\": [5, 8]}},\n",
    "  {{\"word\": \"dog\", \"class\": \"object\", \"object_ids\": [7]}},\n",
    "  {{\"word\": \"cat\", \"class\": \"object\", \"object_ids\": [-1]}},\n",
    "  {{\"word\": \"three\", \"class\": \"count\", \"object_ids\": [2, 3, 4]}},\n",
    "  {{\"word\": \"visible\", \"class\": \"decision_token\", \"object_ids\": [-1]}}\n",
    "]\n",
    "```\n",
    "<image_id>: \n",
    "\n",
    "Inputs:\n",
    "- Question: {question}\n",
    "\n",
    "- Answer: {answer}\n",
    "\n",
    "- Objects in Image: {objects_info}\n",
    "\n",
    "- Candidate Tokens: {candidate_tokens}\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "all_res = []\n",
    "i = 0\n",
    "for inx, row in tqdm(final_df.iterrows()):\n",
    "    question = row[\"question\"]\n",
    "    answer  = row[\"answer\"]\n",
    "    candidate_tokens = row[\"candidates\"]\n",
    "    object_info = row[\"req_info\"]\n",
    "\n",
    "    PROMPT = get_prompt(question, answer, object_info, candidate_tokens)\n",
    "  \n",
    "    res = {\"request\":{\"contents\": [{\"role\": \"user\", \"parts\": [{\"text\": PROMPT}]}], \n",
    "                      \"generationConfig\": {\"temperature\": 0.8, \"topP\": 1, \"maxOutputTokens\": 5000,\"thinking_config\":{\"thinking_budget\":1000}}}}\n",
    "    all_res.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e0a8b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_res)\n",
    "df.to_json(\"/Data2/Arun-UAV/NLP/vision_halu/train_datasets/gemini_batch.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001a100d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29222894",
   "metadata": {},
   "source": [
    "# Uploading files to gcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d038d208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_gcs(local_path: str, gcs_uri: str):\n",
    "    \"\"\"\n",
    "    Upload a local file to a target GCS URI.\n",
    "\n",
    "    Args:\n",
    "        local_path (str): Local file path to upload.\n",
    "        gcs_uri (str): Target GCS URI like 'gs://my-bucket/path/to/upload.txt'\n",
    "        service_account_path (str): Path to GCP service account JSON.\n",
    "    \"\"\"\n",
    "    if not gcs_uri.startswith(\"gs://\"):\n",
    "        raise ValueError(\"Invalid GCS URI. Must start with gs://\")\n",
    "\n",
    "    parts = gcs_uri[5:].split(\"/\", 1)\n",
    "    bucket_name = parts[0]\n",
    "    blob_name = parts[1]\n",
    "\n",
    "    bucket = client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    blob.upload_from_filename(local_path)\n",
    "\n",
    "    print(f\"âœ… Uploaded {local_path} â†’ {gcs_uri}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8cf3a673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Uploaded /Data2/Arun-UAV/NLP/vision_halu/train_datasets/gemini_batch.jsonl â†’ gs://train_data_vision_1/gemini_batch_info/gemini_batch.jsonl\n"
     ]
    }
   ],
   "source": [
    "upload_to_gcs(local_path=\"/Data2/Arun-UAV/NLP/vision_halu/train_datasets/gemini_batch.jsonl\", gcs_uri = \"gs://train_data_vision_1/gemini_batch_info/gemini_batch.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf87eca",
   "metadata": {},
   "source": [
    "# start batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9efc5935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job name: projects/358874265041/locations/us-central1/batchPredictionJobs/8230525080061345792\n",
      "Job state: JOB_STATE_PENDING\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from google import genai\n",
    "from google.genai.types import CreateBatchJobConfig, JobState, HttpOptions\n",
    "output_uri = \"gs://train_data_vision_1/gemini_batch_info/\"\n",
    "\n",
    "# See the documentation: https://googleapis.github.io/python-genai/genai.html#genai.batches.Batches.create\n",
    "job = gen_client.batches.create(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    src=\"gs://train_data_vision_1/gemini_batch_info/gemini_batch.jsonl\",\n",
    "    config=CreateBatchJobConfig(dest=output_uri),\n",
    ")\n",
    "print(f\"Job name: {job.name}\")\n",
    "print(f\"Job state: {job.state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9126c060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<JobState.JOB_STATE_SUCCEEDED: 'JOB_STATE_SUCCEEDED'>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_info = gen_client.batches.get(name=job.name)\n",
    "job_info.state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf8435",
   "metadata": {},
   "source": [
    "# download batch results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c16b2982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_from_gcs(gcs_uri: str, local_path: str):\n",
    "    \"\"\"\n",
    "    Download a file from GCS based on its gs:// URI.\n",
    "\n",
    "    Args:\n",
    "        gcs_uri (str): GCS URI like 'gs://my-bucket/path/to/file.txt'\n",
    "        local_path (str): Path to store the downloaded file locally.\n",
    "    \"\"\"\n",
    "    # Parse bucket and blob name\n",
    "    if not gcs_uri.startswith(\"gs://\"):\n",
    "        raise ValueError(\"Invalid GCS URI. Must start with gs://\")\n",
    "\n",
    "    parts = gcs_uri[5:].split(\"/\", 1)\n",
    "    bucket_name = parts[0]\n",
    "    blob_name = parts[1]\n",
    "    \n",
    "    bucket = client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
    "    blob.download_to_filename(local_path)\n",
    "\n",
    "    print(f\"âœ… Downloaded {gcs_uri} â†’ {local_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7622509f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Downloaded gs://train_data_vision_1/gemini_batch_info/prediction-model-2025-10-30T11:36:37.902607Z/predictions.jsonl â†’ /Data2/Arun-UAV/NLP/vision_halu/train_datasets/gemini_btach_res.jsonl\n"
     ]
    }
   ],
   "source": [
    "download_from_gcs(gcs_uri=\"gs://train_data_vision_1/gemini_batch_info/prediction-model-2025-10-30T11:36:37.902607Z/predictions.jsonl\", local_path =\"/Data2/Arun-UAV/NLP/vision_halu/train_datasets/gemini_btach_res.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a24bb38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = pd.read_json(\"/Data2/Arun-UAV/NLP/vision_halu/train_datasets/gemini_btach_res.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "4f77d153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request</th>\n",
       "      <th>status</th>\n",
       "      <th>response</th>\n",
       "      <th>processed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'contents': [{'parts': [{'text': '\\nYou are g...</td>\n",
       "      <td></td>\n",
       "      <td>{'candidates': [{'avgLogprobs': -0.05581432005...</td>\n",
       "      <td>2025-10-30 11:43:00.463000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'contents': [{'parts': [{'text': '\\nYou are g...</td>\n",
       "      <td></td>\n",
       "      <td>{'candidates': [{'avgLogprobs': -0.04954319887...</td>\n",
       "      <td>2025-10-30 11:43:00.482000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'contents': [{'parts': [{'text': '\\nYou are g...</td>\n",
       "      <td></td>\n",
       "      <td>{'candidates': [{'avgLogprobs': -0.06469375922...</td>\n",
       "      <td>2025-10-30 11:43:00.492000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'contents': [{'parts': [{'text': '\\nYou are g...</td>\n",
       "      <td></td>\n",
       "      <td>{'candidates': [{'avgLogprobs': -0.05808878598...</td>\n",
       "      <td>2025-10-30 11:43:00.488000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'contents': [{'parts': [{'text': '\\nYou are g...</td>\n",
       "      <td></td>\n",
       "      <td>{'candidates': [{'avgLogprobs': -0.05786834847...</td>\n",
       "      <td>2025-10-30 11:43:00.531000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             request status  \\\n",
       "0  {'contents': [{'parts': [{'text': '\\nYou are g...          \n",
       "1  {'contents': [{'parts': [{'text': '\\nYou are g...          \n",
       "2  {'contents': [{'parts': [{'text': '\\nYou are g...          \n",
       "3  {'contents': [{'parts': [{'text': '\\nYou are g...          \n",
       "4  {'contents': [{'parts': [{'text': '\\nYou are g...          \n",
       "\n",
       "                                            response  \\\n",
       "0  {'candidates': [{'avgLogprobs': -0.05581432005...   \n",
       "1  {'candidates': [{'avgLogprobs': -0.04954319887...   \n",
       "2  {'candidates': [{'avgLogprobs': -0.06469375922...   \n",
       "3  {'candidates': [{'avgLogprobs': -0.05808878598...   \n",
       "4  {'candidates': [{'avgLogprobs': -0.05786834847...   \n",
       "\n",
       "                    processed_time  \n",
       "0 2025-10-30 11:43:00.463000+00:00  \n",
       "1 2025-10-30 11:43:00.482000+00:00  \n",
       "2 2025-10-30 11:43:00.492000+00:00  \n",
       "3 2025-10-30 11:43:00.488000+00:00  \n",
       "4 2025-10-30 11:43:00.531000+00:00  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c957e652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_2_bbox(res, objects_df):\n",
    "    bb_box_info = []\n",
    "    for row in res:\n",
    "        obj_ids = row[\"object_ids\"]\n",
    "        bbox = objects_df[objects_df[\"object_id\"].isin(obj_ids)][[\"h\", \"w\", \"y\", \"x\"]].to_dict(orient=\"records\")\n",
    "        bb_box_info.append({\"word\": row[\"word\"], 'class': row[\"class\"], \"bbox\": bbox})\n",
    "    return bb_box_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d5ee3ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>image_path</th>\n",
       "      <th>candidates</th>\n",
       "      <th>hallucination_candidates</th>\n",
       "      <th>object_info</th>\n",
       "      <th>req_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COCO_train2014_000000321493.jpg</td>\n",
       "      <td>Please describe this image in detail.</td>\n",
       "      <td>This outdoor scene captures a bright, clear da...</td>\n",
       "      <td>/Data2/Arun-UAV/NLP/vision_halu/train_datasets...</td>\n",
       "      <td>['outdoor', 'bright', 'clear', 'day', 'sprawli...</td>\n",
       "      <td>['concentration', 'effort', 'overhead', 'behin...</td>\n",
       "      <td>[{'ann_id': 74336, 'category_id': 21, 'categor...</td>\n",
       "      <td>[{'object_id': 21, 'object': 'cow'}, {'object_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COCO_train2014_000000405541.jpg</td>\n",
       "      <td>Please describe this image in detail.</td>\n",
       "      <td>The indoor scene captures a striking Siamese c...</td>\n",
       "      <td>/Data2/Arun-UAV/NLP/vision_halu/train_datasets...</td>\n",
       "      <td>['indoor', 'siamese', 'cat', 'snowshoe', 'loun...</td>\n",
       "      <td>['caramel-colored', 'fluffy', 'pink', 'art', '...</td>\n",
       "      <td>[{'ann_id': 19215, 'category_id': 64, 'categor...</td>\n",
       "      <td>[{'object_id': 64, 'object': 'potted plant'}, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          image_id                               question  \\\n",
       "0  COCO_train2014_000000321493.jpg  Please describe this image in detail.   \n",
       "1  COCO_train2014_000000405541.jpg  Please describe this image in detail.   \n",
       "\n",
       "                                              answer  \\\n",
       "0  This outdoor scene captures a bright, clear da...   \n",
       "1  The indoor scene captures a striking Siamese c...   \n",
       "\n",
       "                                          image_path  \\\n",
       "0  /Data2/Arun-UAV/NLP/vision_halu/train_datasets...   \n",
       "1  /Data2/Arun-UAV/NLP/vision_halu/train_datasets...   \n",
       "\n",
       "                                          candidates  \\\n",
       "0  ['outdoor', 'bright', 'clear', 'day', 'sprawli...   \n",
       "1  ['indoor', 'siamese', 'cat', 'snowshoe', 'loun...   \n",
       "\n",
       "                            hallucination_candidates  \\\n",
       "0  ['concentration', 'effort', 'overhead', 'behin...   \n",
       "1  ['caramel-colored', 'fluffy', 'pink', 'art', '...   \n",
       "\n",
       "                                         object_info  \\\n",
       "0  [{'ann_id': 74336, 'category_id': 21, 'categor...   \n",
       "1  [{'ann_id': 19215, 'category_id': 64, 'categor...   \n",
       "\n",
       "                                            req_info  \n",
       "0  [{'object_id': 21, 'object': 'cow'}, {'object_...  \n",
       "1  [{'object_id': 64, 'object': 'potted plant'}, ...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2a55be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1b33723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = res_df[res_df[\"object_ids\"].apply(lambda x: False if x == [-1] else True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c0fed2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bb_info (res_df, object_df):\n",
    "    all_res_df = []\n",
    "    for inx, row in res_df.iterrows():\n",
    "        obj_ids = row[\"object_ids\"]\n",
    "        req_bbs = []\n",
    "        for _id in obj_ids:\n",
    "            bbs = object_df[object_df[\"category_id\"] == str(_id)][\"bbox_xyxy\"].to_list()\n",
    "            req_bbs.extend(bbs)\n",
    "        all_res_df.append(req_bbs)\n",
    "    return all_res_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d6424366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14435it [03:31, 68.27it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "all_res = []\n",
    "error = 0\n",
    "for inx, row in tqdm(pred_data.iloc[0:].iterrows()):\n",
    "    try:\n",
    "        res = eval(row[\"response\"][\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"].replace(\"json\", \"\").strip(\"```\"))\n",
    "        answer = row[\"request\"][\"contents\"][0][\"parts\"][0][\"text\"].split(\"- Answer:\")[-1].split(\"- Objects in Image:\")[0].strip()\n",
    "        req_info = final_df[final_df[\"answer\"] == answer]\n",
    "        question = req_info[\"question\"].values[0]\n",
    "        object_info = req_info[\"object_info\"].values[0]\n",
    "        object_df = pd.DataFrame(object_info)\n",
    "        object_df[\"category_id\"] = object_df[\"category_id\"].apply(lambda x: str(int(x)))\n",
    "        image_id = req_info[\"image_id\"].values[0]\n",
    "        image_path = req_info[\"image_path\"].values[0]\n",
    "    \n",
    "        res_df = pd.DataFrame(res)\n",
    "        res_df = res_df[res_df[\"object_ids\"].apply(lambda x: False if x == [-1] else True)]\n",
    "        bb_info = get_bb_info(res_df, object_df)\n",
    "        res_df[\"bb_info\"] = bb_info\n",
    "    \n",
    "        res_df = res_df[[\"word\", \"class\", \"bb_info\"]]\n",
    "        target_words = res_df.to_dict(orient=\"records\")\n",
    "    \n",
    "        all_res.append({\n",
    "            \"image_id\": image_id,\n",
    "            \"question\": question,\n",
    "            \"answer\": answer,\n",
    "            \"target_words\": target_words,\n",
    "            \"image_path\": image_path\n",
    "        })\n",
    "    except Exception as e:\n",
    "        error += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b897f1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2cfd50f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>target_words</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COCO_train2014_000000557315.jpg</td>\n",
       "      <td>Please describe this image in detail.</td>\n",
       "      <td>This outdoor scene captures a black bear in wh...</td>\n",
       "      <td>[{'word': 'black', 'class': 'attribute', 'bb_i...</td>\n",
       "      <td>/Data2/Arun-UAV/NLP/vision_halu/train_datasets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COCO_train2014_000000106639.jpg</td>\n",
       "      <td>Please describe this image in detail.</td>\n",
       "      <td>The image presents an inviting indoor scene, l...</td>\n",
       "      <td>[{'word': 'dining', 'class': 'attribute', 'bb_...</td>\n",
       "      <td>/Data2/Arun-UAV/NLP/vision_halu/train_datasets...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          image_id                               question  \\\n",
       "0  COCO_train2014_000000557315.jpg  Please describe this image in detail.   \n",
       "1  COCO_train2014_000000106639.jpg  Please describe this image in detail.   \n",
       "\n",
       "                                              answer  \\\n",
       "0  This outdoor scene captures a black bear in wh...   \n",
       "1  The image presents an inviting indoor scene, l...   \n",
       "\n",
       "                                        target_words  \\\n",
       "0  [{'word': 'black', 'class': 'attribute', 'bb_i...   \n",
       "1  [{'word': 'dining', 'class': 'attribute', 'bb_...   \n",
       "\n",
       "                                          image_path  \n",
       "0  /Data2/Arun-UAV/NLP/vision_halu/train_datasets...  \n",
       "1  /Data2/Arun-UAV/NLP/vision_halu/train_datasets...  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a1318849",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_res_df = pd.DataFrame(all_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "81980062",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_res_df = total_res_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "82146da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bb_info_to_xyxy(data):\n",
    "    \"\"\"\n",
    "    Converts list of dicts with 'bb_info' [[x1, y1, x2, y2], ...]\n",
    "    into explicit bbox dicts: [{'xmin':, 'ymin':, 'xmax':, 'ymax':}, ...]\n",
    "\n",
    "    Args:\n",
    "        data (list[dict]): Each element like:\n",
    "            {'word': str, 'class': str, 'bb_info': [[x1, y1, x2, y2], ...]}\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: Converted list with structure:\n",
    "            [{'word': str,\n",
    "              'class': str,\n",
    "              'bbox': [{'xmin':, 'ymin':, 'xmax':, 'ymax':}, ...]}]\n",
    "    \"\"\"\n",
    "    converted = []\n",
    "    for item in data:\n",
    "        word = item.get(\"word\", \"\")\n",
    "        cls = item.get(\"class\", \"\")\n",
    "        bb_info = item.get(\"bb_info\", [])\n",
    "\n",
    "        # Safely convert all bounding boxes\n",
    "        bbox_list = []\n",
    "        for bb in bb_info:\n",
    "            if len(bb) == 4:\n",
    "                xmin, ymin, xmax, ymax = map(int, bb)\n",
    "                bbox_list.append({\n",
    "                    \"xmin\": xmin,\n",
    "                    \"ymin\": ymin,\n",
    "                    \"xmax\": xmax,\n",
    "                    \"ymax\": ymax\n",
    "                })\n",
    "            else:\n",
    "                # handle malformed bbox gracefully\n",
    "                bbox_list.append({\n",
    "                    \"xmin\": 0, \"ymin\": 0, \"xmax\": 0, \"ymax\": 0\n",
    "                })\n",
    "\n",
    "        converted.append({\n",
    "            \"word\": word,\n",
    "            \"class\": cls,\n",
    "            \"bbox\": bbox_list\n",
    "        })\n",
    "\n",
    "    return converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "d36d64b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13943/13943 [00:04<00:00, 3418.02it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "converted_data = []\n",
    "for i in tqdm(total_res_df[\"target_words\"]):\n",
    "    converted_data.append(convert_bb_info_to_xyxy(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "0dbebf7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13943"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(converted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "aafe443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_res_df[\"target_words\"] = converted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e4a9cfdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>target_words</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COCO_train2014_000000557315.jpg</td>\n",
       "      <td>Please describe this image in detail.</td>\n",
       "      <td>This outdoor scene captures a black bear in wh...</td>\n",
       "      <td>[{'word': 'black', 'class': 'attribute', 'bbox...</td>\n",
       "      <td>/Data2/Arun-UAV/NLP/vision_halu/train_datasets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COCO_train2014_000000106639.jpg</td>\n",
       "      <td>Please describe this image in detail.</td>\n",
       "      <td>The image presents an inviting indoor scene, l...</td>\n",
       "      <td>[{'word': 'dining', 'class': 'attribute', 'bbo...</td>\n",
       "      <td>/Data2/Arun-UAV/NLP/vision_halu/train_datasets...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          image_id                               question  \\\n",
       "0  COCO_train2014_000000557315.jpg  Please describe this image in detail.   \n",
       "1  COCO_train2014_000000106639.jpg  Please describe this image in detail.   \n",
       "\n",
       "                                              answer  \\\n",
       "0  This outdoor scene captures a black bear in wh...   \n",
       "1  The image presents an inviting indoor scene, l...   \n",
       "\n",
       "                                        target_words  \\\n",
       "0  [{'word': 'black', 'class': 'attribute', 'bbox...   \n",
       "1  [{'word': 'dining', 'class': 'attribute', 'bbo...   \n",
       "\n",
       "                                          image_path  \n",
       "0  /Data2/Arun-UAV/NLP/vision_halu/train_datasets...  \n",
       "1  /Data2/Arun-UAV/NLP/vision_halu/train_datasets...  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_res_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "4ee7326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_res_df.to_csv(\"/Data2/Arun-UAV/NLP/vision_halu/evidence_head_train_datasets/coco_long_captions/coco_img_des_10k_bb_annot.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5971bca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ce5e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5a0d87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Data2/Arun-UAV/NLP/vision_halu/evidence_head_train_datasets/flicker/train_processed_flickr_30k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cab3006a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>caption</th>\n",
       "      <th>question</th>\n",
       "      <th>expanded_labels</th>\n",
       "      <th>image_id</th>\n",
       "      <th>bb_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Three people are on a sidewalk.</td>\n",
       "      <td>How many people are on the sidewalk?</td>\n",
       "      <td>{'Three': '4934', 'people': '4934', 'sidewalk'...</td>\n",
       "      <td>1191423753</td>\n",
       "      <td>image_id        filename phrase obje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Beautiful brunette woman, draped in purple, bl...</td>\n",
       "      <td>What colors are the scarves draped around the ...</td>\n",
       "      <td>{'Beautiful': '9911', 'brunette': '9911', 'wom...</td>\n",
       "      <td>1360456780</td>\n",
       "      <td>image_id        filename phrase objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A woman is welding metal at a work table.</td>\n",
       "      <td>What is the woman doing at the work table?</td>\n",
       "      <td>{'woman': '22853', 'metal': '22855', 'work': '...</td>\n",
       "      <td>1897067588</td>\n",
       "      <td>image_id        filename phrase obje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A girl in a white shirt is holding a ball and ...</td>\n",
       "      <td>What is the girl pointing at?</td>\n",
       "      <td>{'girl': '27660', 'white': '27663', 'shirt': '...</td>\n",
       "      <td>208472767</td>\n",
       "      <td>image_id       filename phrase object...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The large, dark colored dog is doing a climbin...</td>\n",
       "      <td>What is the large, dark-colored dog doing?</td>\n",
       "      <td>{'large': '32430', 'dark': '32430', 'colored':...</td>\n",
       "      <td>2176364472</td>\n",
       "      <td>image_id        filename phrase obje...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            caption  \\\n",
       "0           0                    Three people are on a sidewalk.   \n",
       "1           1  Beautiful brunette woman, draped in purple, bl...   \n",
       "2           2          A woman is welding metal at a work table.   \n",
       "3           3  A girl in a white shirt is holding a ball and ...   \n",
       "4           4  The large, dark colored dog is doing a climbin...   \n",
       "\n",
       "                                            question  \\\n",
       "0               How many people are on the sidewalk?   \n",
       "1  What colors are the scarves draped around the ...   \n",
       "2         What is the woman doing at the work table?   \n",
       "3                      What is the girl pointing at?   \n",
       "4         What is the large, dark-colored dog doing?   \n",
       "\n",
       "                                     expanded_labels    image_id  \\\n",
       "0  {'Three': '4934', 'people': '4934', 'sidewalk'...  1191423753   \n",
       "1  {'Beautiful': '9911', 'brunette': '9911', 'wom...  1360456780   \n",
       "2  {'woman': '22853', 'metal': '22855', 'work': '...  1897067588   \n",
       "3  {'girl': '27660', 'white': '27663', 'shirt': '...   208472767   \n",
       "4  {'large': '32430', 'dark': '32430', 'colored':...  2176364472   \n",
       "\n",
       "                                               bb_df  \n",
       "0            image_id        filename phrase obje...  \n",
       "1           image_id        filename phrase objec...  \n",
       "2            image_id        filename phrase obje...  \n",
       "3           image_id       filename phrase object...  \n",
       "4            image_id        filename phrase obje...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326ed6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a94496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there a person behind the street lamp?\n",
      "The street lamp is the focal point, but there is a person bent down directly behind the lamp.\n",
      "{'street': '218332', 'lamp': '218332', 'focal': '218334', 'point': '218334', 'person': '218336'}\n"
     ]
    }
   ],
   "source": [
    "i = 10\n",
    "print(df[\"question\"].iloc[i])\n",
    "print(df[\"caption\"].iloc[i])\n",
    "print(df[\"expanded_labels\"].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcac0288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'          image_id        filename  phrase object_name  xmin  ymin  xmax  \\\\\\n228801  4919450790  4919450790.jpg  218328      218328     2   208   500   \\n228802  4919450790  4919450790.jpg  218329      218329     5   191   497   \\n228803  4919450790  4919450790.jpg  218330      218330   299    29   500   \\n228804  4919450790  4919450790.jpg  218332      218332   260    79   288   \\n228805  4919450790  4919450790.jpg  218335      218335   262    81   282   \\n228806  4919450790  4919450790.jpg  218336      218336   217   182   240   \\n\\n        ymax  width  height                                          sentences  \\n228801   229    500     271  [[/EN#218326/scene A city] with [/EN#218330/sc...  \\n228802   258    500     271  [[/EN#218326/scene A city] with [/EN#218330/sc...  \\n228803   225    500     271  [[/EN#218326/scene A city] with [/EN#218330/sc...  \\n228804   193    500     271  [[/EN#218326/scene A city] with [/EN#218330/sc...  \\n228805   225    500     271  [[/EN#218326/scene A city] with [/EN#218330/sc...  \\n228806   220    500     271  [[/EN#218326/scene A city] with [/EN#218330/sc...  '"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"bb_df\"].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dedc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981a0505",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_str = df[\"bb_df\"].iloc[i]\n",
    "nested_df = pd.read_fwf(StringIO(nested_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0db25ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934897e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shdm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
