{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721b30e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2cdd1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Data2/Arun-UAV/NLP/vision_halu/haloc/haloc_extension/caption/gemini_labeled_28k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f03ac98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>candidates</th>\n",
       "      <th>hallucination_candidates</th>\n",
       "      <th>candidates_inx</th>\n",
       "      <th>hallucination_candidates_inx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2381430.jpg</td>\n",
       "      <td>What do you think is going on in this snapshot?</td>\n",
       "      <td>In this picture we can see one woman is holdin...</td>\n",
       "      <td>['holding', 'playing', 'fencing', 'tennis', 'b...</td>\n",
       "      <td>['bat']</td>\n",
       "      <td>{'holding': [(40, 47)], 'playing': [(58, 65)],...</td>\n",
       "      <td>{'bat': [(50, 53)]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381430.jpg</td>\n",
       "      <td>What do you think is going on in this snapshot?</td>\n",
       "      <td>In this picture we can see one woman is holdin...</td>\n",
       "      <td>['ground', 'holding', 'playing', 'fencing', 't...</td>\n",
       "      <td>['frisbee', 'bat']</td>\n",
       "      <td>{'ground': [(114, 120)], 'holding': [(40, 47)]...</td>\n",
       "      <td>{'frisbee': [(99, 106)], 'bat': [(50, 53)]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_path                                         question  \\\n",
       "0  2381430.jpg  What do you think is going on in this snapshot?   \n",
       "1  2381430.jpg  What do you think is going on in this snapshot?   \n",
       "\n",
       "                                              answer  \\\n",
       "0  In this picture we can see one woman is holdin...   \n",
       "1  In this picture we can see one woman is holdin...   \n",
       "\n",
       "                                          candidates hallucination_candidates  \\\n",
       "0  ['holding', 'playing', 'fencing', 'tennis', 'b...                  ['bat']   \n",
       "1  ['ground', 'holding', 'playing', 'fencing', 't...       ['frisbee', 'bat']   \n",
       "\n",
       "                                      candidates_inx  \\\n",
       "0  {'holding': [(40, 47)], 'playing': [(58, 65)],...   \n",
       "1  {'ground': [(114, 120)], 'holding': [(40, 47)]...   \n",
       "\n",
       "                  hallucination_candidates_inx  \n",
       "0                          {'bat': [(50, 53)]}  \n",
       "1  {'frisbee': [(99, 106)], 'bat': [(50, 53)]}  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb966bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.conda/envs/shdm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "def spans_to_token_indices(tokenizer, text, spans):\n",
    "    \"\"\"\n",
    "    Map character-level spans to token index spans after tokenization.\n",
    "    spans: list of (start_char, end_char) with end exclusive.\n",
    "    Returns list of (tok_start, tok_end) inclusive in the tokenized sequence (with special tokens).\n",
    "    \"\"\"\n",
    "    enc = tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        return_offsets_mapping=True  # not strictly required for char_to_token, but useful for debug\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    for (start_char, end_char) in spans:\n",
    "        # Map to token indices (inclusive)\n",
    "        tok_start = enc.char_to_token(start_char)\n",
    "        tok_end   = enc.char_to_token(end_char - 1)\n",
    "\n",
    "        # If either is None, try to nudge inward/outward a bit (rare, but can happen around spaces)\n",
    "        if tok_start is None:\n",
    "            # Move forward until we hit a mappable character or run out\n",
    "            i = start_char\n",
    "            while i < end_char and tok_start is None:\n",
    "                i += 1\n",
    "                tok_start = enc.char_to_token(i)\n",
    "        if tok_end is None:\n",
    "            # Move backward until we hit a mappable character or run out\n",
    "            i = end_char - 1\n",
    "            while i >= start_char and tok_end is None:\n",
    "                i -= 1\n",
    "                tok_end = enc.char_to_token(i)\n",
    "\n",
    "        # Final fallback: if still None, the span didn’t map to any token (e.g., only spaces/punct removed)\n",
    "        if tok_start is None or tok_end is None:\n",
    "            results.append((None, None))\n",
    "        else:\n",
    "            results.append((tok_start, tok_end))\n",
    "    return enc, results\n",
    "\n",
    "# # --- Example ---\n",
    "# # Choose any fast tokenizer; BERT shown here.\n",
    "# tok = AutoTokenizer.from_pretrained(\"bert-base-uncased\", use_fast=True)\n",
    "\n",
    "\n",
    "\n",
    "# enc, token_spans = spans_to_token_indices(tok, text, spans)\n",
    "\n",
    "# print(enc.input_ids)         # includes [CLS] ... [SEP]\n",
    "# print(token_spans)           # e.g., [(1,1), (4,6), (7,7)] depending on subword splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c64a28d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.conda/envs/shdm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# model_path = \"liuhaotian/llava-v1.5-7b\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "578937ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = data[\"answer\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebd375dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> In this picture we can see one woman is holding a bat and playing tennis. Back side, we can see fencing.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer(sen)[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40addc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"USER: Hello ASSISTANT: How are you ASSISTANT: fine\"\n",
    "token = \"ASSISTANT\"\n",
    "\n",
    "# Find the first index of the token\n",
    "text.find(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f45a20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'USER: Hello '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2e48101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.conda/envs/shdm/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"liuhaotian/llava-v1.5-7b\"\n",
    "\n",
    "# ✅ Force fast tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, padding_side=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "372b91fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tokenizer(text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1076876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"input_ids\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2f941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83265768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"token\": [\"bat\", \"holding\", \"one\", \"playing\", \"tennis\", \"side\", \"woman\", \"back\", \"fencing\"],\n",
    "    \"mat_tokens\": [[155], [153], [150], [157], [158], [161], [151], [160], [166, 167]],\n",
    "    \"label\": [-1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "})\n",
    "\n",
    "# Step 1: explode mat_tokens so each token ID gets its own row\n",
    "exploded = df.explode(\"mat_tokens\")\n",
    "\n",
    "# Step 2: group by mat_token id and compute majority label\n",
    "def majority_label(labels):\n",
    "    counts = Counter(labels)\n",
    "    return counts.most_common(1)[0][0]\n",
    "\n",
    "mapping = (exploded.groupby(\"mat_tokens\")[\"label\"].apply(majority_label).to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07cbfed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{150: 1,\n",
       " 151: 1,\n",
       " 153: 1,\n",
       " 155: -1,\n",
       " 157: 1,\n",
       " 158: 1,\n",
       " 160: 1,\n",
       " 161: 1,\n",
       " 166: 1,\n",
       " 167: 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e30bc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Updated: tensor([  1,   2,   3,  20,  50, 100,   5,   6,   7,   8,   9])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example tensor\n",
    "t = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "print(\"Original:\", t)\n",
    "\n",
    "# Position and new values\n",
    "idx = 3                 # position to replace (value 4)\n",
    "new_values = torch.tensor([20, 50, 100])\n",
    "\n",
    "# Create new tensor\n",
    "result = torch.cat([t[:idx], new_values, t[idx+1:]])\n",
    "print(\"Updated:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1a35f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original batch shape: torch.Size([2, 8])\n",
      "Expanded batch shape: torch.Size([2, 383])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb01d4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_tensor = torch.tensor([1, 2, 3, 4, 5])\n",
    "insert_tensor = torch.tensor([99, 100])\n",
    "position = 2  # insert before index 2 (i.e., between 2 and 3)\n",
    "\n",
    "# ✅ Insert using torch.cat\n",
    "result = torch.cat((main_tensor[:position], insert_tensor, main_tensor[position:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46d3292b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-200, -200, -200, -200, -200])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "tensor = torch.full((5,), -200)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "091be7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec28bd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(a == 2)[0].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2d48b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df  = pd.read_json(\"/Data2/Arun-UAV/NLP/vision_halu/haloc/embeddings/caption/llava_24/batch_4eec170b-1c8f-4bc1-b4c8-747a7d60b263.jsonl\", lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1264192c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7def9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e49dd4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shdm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
